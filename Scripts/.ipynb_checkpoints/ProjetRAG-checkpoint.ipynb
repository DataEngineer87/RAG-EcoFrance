{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "327bdc83-14e8-48f6-a882-847e4846e8c4",
   "metadata": {},
   "source": [
    "# Chatbot RAG - Économie Française\n",
    "Ce projet porte la mise en place d’un chatbot intelligent capable d’interroger un rapport PDF en langage naturel.\n",
    "L’architecture repose sur une approche RAG (Retrieval-Augmented Generation), qui combine la recherche d’informations pertinentes dans un document et la génération de réponses contextuelles grâce à un modèle de langage.\n",
    "\n",
    "Technologies utilisées :\n",
    "\n",
    "- Ollama (Mistral) : génération d’embeddings et production de réponses en français\n",
    "\n",
    "- FAISS : moteur de recherche vectorielle pour retrouver les passages les plus pertinents du document\n",
    "\n",
    "- Streamlit : interface web interactive et conviviale permettant d’interagir avec le chatbot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e6f58f4-f1dc-4a3f-8229-21dc755a2be2",
   "metadata": {},
   "source": [
    "## Création des fichiers docs.index et docs.json pour l’indexation des documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d13cbc29-2772-4f2f-8278-ed8ee351dfcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usage: exécution après avoir lancé \"ollama serve\" et téléchargé le modèle mistral.\n",
    "\n",
    "from pypdf import PdfReader\n",
    "import ollama\n",
    "import numpy as np\n",
    "import faiss\n",
    "import json\n",
    "import os\n",
    "from tqdm import tqdm  # pas obligatoir mais pratique pour voir l'avancement\n",
    "\n",
    "# Configuration \n",
    "pdf_path = \"/home/sacko/Documents/Chatbot RAG -EConomie-Française/Fichiers/ECO_FRANCE.pdf\"   # chemin vers le fichier PDF\n",
    "model = \"mistral\"\n",
    "chunk_size = 800       # taille en caractères par chunk \n",
    "chunk_overlap = 200    # recouvrement entre chunks\n",
    "index_file = \"docs.index\"\n",
    "docs_file = \"docs.json\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da85fabb-0fd0-43d2-a833-53cfd68e9b35",
   "metadata": {},
   "source": [
    "## Extraction automatique du contenu d’un rapport PDF pour l’analyse IA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9bc265ca-ef50-47f5-849a-636c35ba9526",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Texte extrait : 24313 caractères, 13 pages\n"
     ]
    }
   ],
   "source": [
    "# Extraction du contenu textuel d’un PDF\n",
    "reader = PdfReader(pdf_path)\n",
    "pages = [p.extract_text() for p in reader.pages]\n",
    "pages = [p for p in pages if p]  # Exclusion des pages vides lors de l’extraction\n",
    "full_text = \"\\n\\n\".join(pages)\n",
    "print(f\"Texte extrait : {len(full_text)} caractères, {len(pages)} pages\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b94eabaf-0248-4bd7-b596-e1faf1cd4fbd",
   "metadata": {},
   "source": [
    "## Prétraitement et découpage des textes afin d’alimenter le moteur RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c01d75ae-1b04-4efe-bc0f-a696e76bca49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41 chunks créés (chunk_size=800, overlap=200)\n"
     ]
    }
   ],
   "source": [
    "# Découpage en chunks\n",
    "def chunk_text(text, chunk_size=800, overlap=200):\n",
    "    chunks = []\n",
    "    start = 0\n",
    "    L = len(text)\n",
    "    while start < L:\n",
    "        end = min(start + chunk_size, L)\n",
    "        chunk = text[start:end].strip()\n",
    "        if chunk:\n",
    "            chunks.append(chunk)\n",
    "        start += chunk_size - overlap\n",
    "    return chunks\n",
    "\n",
    "chunks = chunk_text(full_text, chunk_size=chunk_size, overlap=chunk_overlap)\n",
    "print(f\"{len(chunks)} chunks créés (chunk_size={chunk_size}, overlap={chunk_overlap})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd332c45-2a65-4098-a8f1-c8cbf2368242",
   "metadata": {},
   "source": [
    "##  Production des vecteurs d’embedding via Ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f63e79df-464c-49d1-a99b-8725b9b51e04",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Embeddings: 100%|█████████████████████████████████████████████████████████████████████████████████| 41/41 [04:32<00:00,  6.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings shape: (41, 4096)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# On s'assure que le serveur Ollama est en cours d’exécution et que le modèle mistral a bien été téléchargé (ollama pull mistral).\n",
    "embeddings = []\n",
    "for chunk in tqdm(chunks, desc=\"Embeddings\"):\n",
    "    resp = ollama.embed(model=model, input=chunk)\n",
    "    \n",
    "# Le nom de la clé varie selon la version du SDK : embedding pour un vecteur unique ou embeddings pour une liste. Notre code gère les deux.    if \"embeddings\" in resp:\n",
    "        emb = resp[\"embeddings\"][0]\n",
    "    elif \"embedding\" in resp:\n",
    "        emb = resp[\"embedding\"]\n",
    "    else:\n",
    "        raise RuntimeError(\"Format d'embedding inattendu : %s\" % resp)\n",
    "    embeddings.append(emb)\n",
    "\n",
    "embeddings = np.array(embeddings, dtype=\"float32\")\n",
    "print(\"Embeddings shape:\", embeddings.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9597f569-bf83-491c-9f47-ab49a735b947",
   "metadata": {},
   "source": [
    "## Construire l'index FAISS et sauvegarder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "696c109d-0918-4fee-a17d-f158517995c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index sauvegardé: docs.index\n",
      "Chunks sauvegardés: docs.json\n"
     ]
    }
   ],
   "source": [
    "# Indexation FAISS et enregistrement du fichier d’index\n",
    "d = embeddings.shape[1]\n",
    "index = faiss.IndexFlatL2(d)  # index simple L2 \n",
    "index.add(embeddings)\n",
    "faiss.write_index(index, index_file)\n",
    "print(\"Index sauvegardé:\", index_file)\n",
    "\n",
    "# 5) Sauvegarde des chunks (id -> texte)\n",
    "with open(docs_file, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(chunks, f, ensure_ascii=False, indent=2)\n",
    "print(\"Chunks sauvegardés:\", docs_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7f51812c-d00e-4c2c-99b6-e768f1073456",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Réponse :  Les facteurs influençant l'économie française peuvent être identifiés à partir du contexte fourni. Voici une liste de quelques facteurs :\n",
      "\n",
      "1. La politique fiscale et sociale d'autres pays européens, comme en Allemagne avec la baisse des cotisations sociales, peut affecter l'économie française en créant une compétitivité disproportionnée qui peut entraîner un ralentissement de l'activité dans le pays (chunk 36).\n",
      "2. La crise financière des années 2008 et 2009 a laissé des déficits importants et une dette publique considérablement accrue en Europe, y compris en France, créant ainsi des défis à l'intérieur de l'Union européenne (chunk 36).\n",
      "3. Les changements dans les politiques économiques peuvent avoir un impact sur la demande et la croissance économique en France. Par exemple, les effets décalés du contre-choc pétrolier de 1985-1986 ont amplifié la reprise qui a débuté à mi-1987 (chunk 16).\n",
      "4. Les conflits internationaux peuvent également avoir un impact sur l'économie française, comme la guerre du Golfe en 1990 et la réunification allemande en 1991 qui ont plongé l'Europe dans une récession (chunk 16).\n",
      "5. Les caractéristiques économiques uniques de chaque pays peuvent également influencer leur performance économique. Par exemple, l'article cité dans le chunk 40 discute des forces dynamiques du développement capitaliste en France.\n"
     ]
    }
   ],
   "source": [
    "query = \"Quels sont les facteurs influençant l'économie française ?\"\n",
    "\n",
    "# Chercher le contexte dans FAISS\n",
    "retrieved = retrieve_context(query, k=3)\n",
    "prompt = build_prompt(query, retrieved)\n",
    "\n",
    "# Appel du modèle Ollama\n",
    "response = ollama.chat(\n",
    "    model=\"mistral\",\n",
    "    messages=[{\"role\":\"user\",\"content\":prompt}]\n",
    ")\n",
    "print(\"Réponse :\", response[\"message\"][\"content\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49df0cfe-3b1f-4f28-af95-b5a8ada5170a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1e42902-e32c-4c9a-b56c-370494fb6947",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eb79dcf-cad4-4919-8aa4-4244e8870d45",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "31385d50-3676-4b6c-be1c-0c5238a31cd0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "246504454df04cf6baeae5d6df6252ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='Quels sont les impacts de l’IA sur l’économie française ?', description='Question:', layout=Layout…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75945db4dcd5471aa82ba2de6868f106",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntSlider(value=3, continuous_update=False, description='Nb docs:', max=10, min=1)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa7fed64c9b94b4db7a316d716cd013c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(button_style='success', description='Poser la question', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a43c3a8e6144e488b5e6a84c5503cb8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import faiss\n",
    "import numpy as np\n",
    "import json\n",
    "import ollama\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "# ⚙️ Config\n",
    "index_file = \"/home/sacko/Documents/ProjetRAG/Scripts/docs.index\"\n",
    "docs_file = \"/home/sacko/Documents/ProjetRAG/Scripts/docs.json\"\n",
    "model = \"mistral\"\n",
    "\n",
    "# 🔄 Charger l'index et les chunks\n",
    "index = faiss.read_index(index_file)\n",
    "with open(docs_file, \"r\", encoding=\"utf-8\") as f:\n",
    "    docs = json.load(f)\n",
    "\n",
    "def retrieve_context(query, k=3):\n",
    "    \"\"\"Recherche les passages pertinents dans FAISS\"\"\"\n",
    "    q_emb = ollama.embed(model=model, input=query)[\"embeddings\"][0]\n",
    "    qv = np.array([q_emb], dtype=\"float32\")\n",
    "    D, I = index.search(qv, k=k)\n",
    "    results = []\n",
    "    for dist, idx in zip(D[0], I[0]):\n",
    "        doc = docs[idx]\n",
    "        results.append({\n",
    "            \"id\": idx,\n",
    "            \"distance\": float(dist),\n",
    "            \"page\": doc[\"page\"],\n",
    "            \"text\": doc[\"text\"]\n",
    "        })\n",
    "    return results\n",
    "\n",
    "def build_prompt(query, retrieved):\n",
    "    \"\"\"Construit le prompt pour le LLM avec consignes de citations\"\"\"\n",
    "    context = \"\\n\\n---\\n\".join(\n",
    "        [f\"[page {r['page']} | dist={r['distance']:.4f}]\\n{r['text']}\" for r in retrieved]\n",
    "    )\n",
    "    prompt = f\"\"\"\n",
    "Tu es un assistant spécialisé en économie française.\n",
    "Voici des extraits du document ECO_FRANCE.pdf avec numéros de page :\n",
    "\n",
    "{context}\n",
    "\n",
    "Question : {query}\n",
    "\n",
    "Consignes :\n",
    "- Réponds de manière claire en français.\n",
    "- Cite les pages pertinentes sous la forme (page X).\n",
    "- Inclue un court extrait exact entre guillemets pour justifier ta réponse.\n",
    "\"\"\"\n",
    "    return prompt\n",
    "\n",
    "def ask(query, k=3):\n",
    "    \"\"\"Fonction principale : récupère, construit prompt et appelle Ollama\"\"\"\n",
    "    retrieved = retrieve_context(query, k=k)\n",
    "    prompt = build_prompt(query, retrieved)\n",
    "    response = ollama.chat(model=model, messages=[{\"role\":\"user\",\"content\":prompt}])\n",
    "    answer = response[\"message\"][\"content\"]\n",
    "\n",
    "    # Affichage\n",
    "    display(Markdown(f\"### 💬 Réponse du modèle :\\n{answer}\"))\n",
    "    print(\"\\n📚 Sources utilisées :\")\n",
    "    for r in retrieved:\n",
    "        print(f\"- Page {r['page']} (score={r['distance']:.4f}) : {r['text'][:200]}...\")\n",
    "\n",
    "# 🎛️ Widgets interactifs\n",
    "text_box = widgets.Text(\n",
    "    value=\"Quels sont les impacts de l’IA sur l’économie française ?\",\n",
    "    placeholder=\"Tape ta question ici...\",\n",
    "    description=\"Question:\",\n",
    "    layout=widgets.Layout(width=\"80%\")\n",
    ")\n",
    "\n",
    "slider_k = widgets.IntSlider(\n",
    "    value=3,\n",
    "    min=1,\n",
    "    max=10,\n",
    "    step=1,\n",
    "    description=\"Nb docs:\",\n",
    "    continuous_update=False\n",
    ")\n",
    "\n",
    "button = widgets.Button(description=\"Poser la question\", button_style=\"success\")\n",
    "output = widgets.Output()\n",
    "\n",
    "def on_button_click(b):\n",
    "    output.clear_output()\n",
    "    with output:\n",
    "        ask(text_box.value, k=slider_k.value)\n",
    "\n",
    "button.on_click(on_button_click)\n",
    "\n",
    "display(text_box, slider_k, button, output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "276c9953-165c-41ac-8326-7ae3b3348895",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9838e96-ed81-459b-846f-fcc25d306730",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df88d745-5fcb-4961-9433-d648957393a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c751727-c938-44ce-882c-c5a4d6dc5185",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7621a300-d475-4945-a24f-a3eb81705fe4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37132470-338e-47c6-8be7-72a0f6fef4f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c680415f-0de8-4682-b227-254d80d56ffa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cec675a9-f12c-4c7a-8466-8f3f470972ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c17c1f0-a3b2-4b52-a677-f0fd642e6d63",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.13 (RAG)",
   "language": "python",
   "name": "rag_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
