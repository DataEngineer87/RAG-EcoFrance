{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "327bdc83-14e8-48f6-a882-847e4846e8c4",
   "metadata": {},
   "source": [
    "# Chatbot RAG - √âconomie Fran√ßaise\n",
    "Ce projet porte la mise en place d‚Äôun chatbot intelligent capable d‚Äôinterroger un rapport PDF en langage naturel.\n",
    "L‚Äôarchitecture repose sur une approche RAG (Retrieval-Augmented Generation), qui combine la recherche d‚Äôinformations pertinentes dans un document et la g√©n√©ration de r√©ponses contextuelles gr√¢ce √† un mod√®le de langage.\n",
    "\n",
    "Technologies utilis√©es :\n",
    "\n",
    "- Ollama (Mistral) : g√©n√©ration d‚Äôembeddings et production de r√©ponses en fran√ßais\n",
    "\n",
    "- FAISS : moteur de recherche vectorielle pour retrouver les passages les plus pertinents du document\n",
    "\n",
    "- Streamlit : interface web interactive et conviviale permettant d‚Äôinteragir avec le chatbot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e6f58f4-f1dc-4a3f-8229-21dc755a2be2",
   "metadata": {},
   "source": [
    "## Cr√©ation des fichiers docs.index et docs.json pour l‚Äôindexation des documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d13cbc29-2772-4f2f-8278-ed8ee351dfcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usage: ex√©cution apr√®s avoir lanc√© \"ollama serve\" et t√©l√©charg√© le mod√®le mistral.\n",
    "\n",
    "from pypdf import PdfReader\n",
    "import ollama\n",
    "import numpy as np\n",
    "import faiss\n",
    "import json\n",
    "import os\n",
    "from tqdm import tqdm  # pas obligatoir mais pratique pour voir l'avancement\n",
    "\n",
    "# Configuration \n",
    "pdf_path = \"/home/sacko/Documents/Chatbot RAG -EConomie-Fran√ßaise/Fichiers/ECO_FRANCE.pdf\"   # chemin vers le fichier PDF\n",
    "model = \"mistral\"\n",
    "chunk_size = 800       # taille en caract√®res par chunk \n",
    "chunk_overlap = 200    # recouvrement entre chunks\n",
    "index_file = \"docs.index\"\n",
    "docs_file = \"docs.json\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da85fabb-0fd0-43d2-a833-53cfd68e9b35",
   "metadata": {},
   "source": [
    "## Extraction automatique du contenu d‚Äôun rapport PDF pour l‚Äôanalyse IA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9bc265ca-ef50-47f5-849a-636c35ba9526",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Texte extrait : 24313 caract√®res, 13 pages\n"
     ]
    }
   ],
   "source": [
    "# Extraction du contenu textuel d‚Äôun PDF\n",
    "reader = PdfReader(pdf_path)\n",
    "pages = [p.extract_text() for p in reader.pages]\n",
    "pages = [p for p in pages if p]  # Exclusion des pages vides lors de l‚Äôextraction\n",
    "full_text = \"\\n\\n\".join(pages)\n",
    "print(f\"Texte extrait : {len(full_text)} caract√®res, {len(pages)} pages\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b94eabaf-0248-4bd7-b596-e1faf1cd4fbd",
   "metadata": {},
   "source": [
    "## Pr√©traitement et d√©coupage des textes afin d‚Äôalimenter le moteur RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c01d75ae-1b04-4efe-bc0f-a696e76bca49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41 chunks cr√©√©s (chunk_size=800, overlap=200)\n"
     ]
    }
   ],
   "source": [
    "# D√©coupage en chunks\n",
    "def chunk_text(text, chunk_size=800, overlap=200):\n",
    "    chunks = []\n",
    "    start = 0\n",
    "    L = len(text)\n",
    "    while start < L:\n",
    "        end = min(start + chunk_size, L)\n",
    "        chunk = text[start:end].strip()\n",
    "        if chunk:\n",
    "            chunks.append(chunk)\n",
    "        start += chunk_size - overlap\n",
    "    return chunks\n",
    "\n",
    "chunks = chunk_text(full_text, chunk_size=chunk_size, overlap=chunk_overlap)\n",
    "print(f\"{len(chunks)} chunks cr√©√©s (chunk_size={chunk_size}, overlap={chunk_overlap})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd332c45-2a65-4098-a8f1-c8cbf2368242",
   "metadata": {},
   "source": [
    "##  Production des vecteurs d‚Äôembedding via Ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f63e79df-464c-49d1-a99b-8725b9b51e04",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Embeddings: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 41/41 [04:32<00:00,  6.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings shape: (41, 4096)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# On s'assure que le serveur Ollama est en cours d‚Äôex√©cution et que le mod√®le mistral a bien √©t√© t√©l√©charg√© (ollama pull mistral).\n",
    "embeddings = []\n",
    "for chunk in tqdm(chunks, desc=\"Embeddings\"):\n",
    "    resp = ollama.embed(model=model, input=chunk)\n",
    "    \n",
    "# Le nom de la cl√© varie selon la version du SDK : embedding pour un vecteur unique ou embeddings pour une liste. Notre code g√®re les deux.    if \"embeddings\" in resp:\n",
    "        emb = resp[\"embeddings\"][0]\n",
    "    elif \"embedding\" in resp:\n",
    "        emb = resp[\"embedding\"]\n",
    "    else:\n",
    "        raise RuntimeError(\"Format d'embedding inattendu : %s\" % resp)\n",
    "    embeddings.append(emb)\n",
    "\n",
    "embeddings = np.array(embeddings, dtype=\"float32\")\n",
    "print(\"Embeddings shape:\", embeddings.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9597f569-bf83-491c-9f47-ab49a735b947",
   "metadata": {},
   "source": [
    "## Construire l'index FAISS et sauvegarder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "696c109d-0918-4fee-a17d-f158517995c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index sauvegard√©: docs.index\n",
      "Chunks sauvegard√©s: docs.json\n"
     ]
    }
   ],
   "source": [
    "# Indexation FAISS et enregistrement du fichier d‚Äôindex\n",
    "d = embeddings.shape[1]\n",
    "index = faiss.IndexFlatL2(d)  # index simple L2 \n",
    "index.add(embeddings)\n",
    "faiss.write_index(index, index_file)\n",
    "print(\"Index sauvegard√©:\", index_file)\n",
    "\n",
    "# 5) Sauvegarde des chunks (id -> texte)\n",
    "with open(docs_file, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(chunks, f, ensure_ascii=False, indent=2)\n",
    "print(\"Chunks sauvegard√©s:\", docs_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7f51812c-d00e-4c2c-99b6-e768f1073456",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R√©ponse :  Les facteurs influen√ßant l'√©conomie fran√ßaise peuvent √™tre identifi√©s √† partir du contexte fourni. Voici une liste de quelques facteurs :\n",
      "\n",
      "1. La politique fiscale et sociale d'autres pays europ√©ens, comme en Allemagne avec la baisse des cotisations sociales, peut affecter l'√©conomie fran√ßaise en cr√©ant une comp√©titivit√© disproportionn√©e qui peut entra√Æner un ralentissement de l'activit√© dans le pays (chunk 36).\n",
      "2. La crise financi√®re des ann√©es 2008 et 2009 a laiss√© des d√©ficits importants et une dette publique consid√©rablement accrue en Europe, y compris en France, cr√©ant ainsi des d√©fis √† l'int√©rieur de l'Union europ√©enne (chunk 36).\n",
      "3. Les changements dans les politiques √©conomiques peuvent avoir un impact sur la demande et la croissance √©conomique en France. Par exemple, les effets d√©cal√©s du contre-choc p√©trolier de 1985-1986 ont amplifi√© la reprise qui a d√©but√© √† mi-1987 (chunk 16).\n",
      "4. Les conflits internationaux peuvent √©galement avoir un impact sur l'√©conomie fran√ßaise, comme la guerre du Golfe en 1990 et la r√©unification allemande en 1991 qui ont plong√© l'Europe dans une r√©cession (chunk 16).\n",
      "5. Les caract√©ristiques √©conomiques uniques de chaque pays peuvent √©galement influencer leur performance √©conomique. Par exemple, l'article cit√© dans le chunk 40 discute des forces dynamiques du d√©veloppement capitaliste en France.\n"
     ]
    }
   ],
   "source": [
    "query = \"Quels sont les facteurs influen√ßant l'√©conomie fran√ßaise ?\"\n",
    "\n",
    "# Chercher le contexte dans FAISS\n",
    "retrieved = retrieve_context(query, k=3)\n",
    "prompt = build_prompt(query, retrieved)\n",
    "\n",
    "# Appel du mod√®le Ollama\n",
    "response = ollama.chat(\n",
    "    model=\"mistral\",\n",
    "    messages=[{\"role\":\"user\",\"content\":prompt}]\n",
    ")\n",
    "print(\"R√©ponse :\", response[\"message\"][\"content\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49df0cfe-3b1f-4f28-af95-b5a8ada5170a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1e42902-e32c-4c9a-b56c-370494fb6947",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eb79dcf-cad4-4919-8aa4-4244e8870d45",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "31385d50-3676-4b6c-be1c-0c5238a31cd0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "246504454df04cf6baeae5d6df6252ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='Quels sont les impacts de l‚ÄôIA sur l‚Äô√©conomie fran√ßaise ?', description='Question:', layout=Layout‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75945db4dcd5471aa82ba2de6868f106",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntSlider(value=3, continuous_update=False, description='Nb docs:', max=10, min=1)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa7fed64c9b94b4db7a316d716cd013c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(button_style='success', description='Poser la question', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a43c3a8e6144e488b5e6a84c5503cb8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import faiss\n",
    "import numpy as np\n",
    "import json\n",
    "import ollama\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "# ‚öôÔ∏è Config\n",
    "index_file = \"/home/sacko/Documents/ProjetRAG/Scripts/docs.index\"\n",
    "docs_file = \"/home/sacko/Documents/ProjetRAG/Scripts/docs.json\"\n",
    "model = \"mistral\"\n",
    "\n",
    "# üîÑ Charger l'index et les chunks\n",
    "index = faiss.read_index(index_file)\n",
    "with open(docs_file, \"r\", encoding=\"utf-8\") as f:\n",
    "    docs = json.load(f)\n",
    "\n",
    "def retrieve_context(query, k=3):\n",
    "    \"\"\"Recherche les passages pertinents dans FAISS\"\"\"\n",
    "    q_emb = ollama.embed(model=model, input=query)[\"embeddings\"][0]\n",
    "    qv = np.array([q_emb], dtype=\"float32\")\n",
    "    D, I = index.search(qv, k=k)\n",
    "    results = []\n",
    "    for dist, idx in zip(D[0], I[0]):\n",
    "        doc = docs[idx]\n",
    "        results.append({\n",
    "            \"id\": idx,\n",
    "            \"distance\": float(dist),\n",
    "            \"page\": doc[\"page\"],\n",
    "            \"text\": doc[\"text\"]\n",
    "        })\n",
    "    return results\n",
    "\n",
    "def build_prompt(query, retrieved):\n",
    "    \"\"\"Construit le prompt pour le LLM avec consignes de citations\"\"\"\n",
    "    context = \"\\n\\n---\\n\".join(\n",
    "        [f\"[page {r['page']} | dist={r['distance']:.4f}]\\n{r['text']}\" for r in retrieved]\n",
    "    )\n",
    "    prompt = f\"\"\"\n",
    "Tu es un assistant sp√©cialis√© en √©conomie fran√ßaise.\n",
    "Voici des extraits du document ECO_FRANCE.pdf avec num√©ros de page :\n",
    "\n",
    "{context}\n",
    "\n",
    "Question : {query}\n",
    "\n",
    "Consignes :\n",
    "- R√©ponds de mani√®re claire en fran√ßais.\n",
    "- Cite les pages pertinentes sous la forme (page X).\n",
    "- Inclue un court extrait exact entre guillemets pour justifier ta r√©ponse.\n",
    "\"\"\"\n",
    "    return prompt\n",
    "\n",
    "def ask(query, k=3):\n",
    "    \"\"\"Fonction principale : r√©cup√®re, construit prompt et appelle Ollama\"\"\"\n",
    "    retrieved = retrieve_context(query, k=k)\n",
    "    prompt = build_prompt(query, retrieved)\n",
    "    response = ollama.chat(model=model, messages=[{\"role\":\"user\",\"content\":prompt}])\n",
    "    answer = response[\"message\"][\"content\"]\n",
    "\n",
    "    # Affichage\n",
    "    display(Markdown(f\"### üí¨ R√©ponse du mod√®le :\\n{answer}\"))\n",
    "    print(\"\\nüìö Sources utilis√©es :\")\n",
    "    for r in retrieved:\n",
    "        print(f\"- Page {r['page']} (score={r['distance']:.4f}) : {r['text'][:200]}...\")\n",
    "\n",
    "# üéõÔ∏è Widgets interactifs\n",
    "text_box = widgets.Text(\n",
    "    value=\"Quels sont les impacts de l‚ÄôIA sur l‚Äô√©conomie fran√ßaise ?\",\n",
    "    placeholder=\"Tape ta question ici...\",\n",
    "    description=\"Question:\",\n",
    "    layout=widgets.Layout(width=\"80%\")\n",
    ")\n",
    "\n",
    "slider_k = widgets.IntSlider(\n",
    "    value=3,\n",
    "    min=1,\n",
    "    max=10,\n",
    "    step=1,\n",
    "    description=\"Nb docs:\",\n",
    "    continuous_update=False\n",
    ")\n",
    "\n",
    "button = widgets.Button(description=\"Poser la question\", button_style=\"success\")\n",
    "output = widgets.Output()\n",
    "\n",
    "def on_button_click(b):\n",
    "    output.clear_output()\n",
    "    with output:\n",
    "        ask(text_box.value, k=slider_k.value)\n",
    "\n",
    "button.on_click(on_button_click)\n",
    "\n",
    "display(text_box, slider_k, button, output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "276c9953-165c-41ac-8326-7ae3b3348895",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9838e96-ed81-459b-846f-fcc25d306730",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df88d745-5fcb-4961-9433-d648957393a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c751727-c938-44ce-882c-c5a4d6dc5185",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7621a300-d475-4945-a24f-a3eb81705fe4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37132470-338e-47c6-8be7-72a0f6fef4f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c680415f-0de8-4682-b227-254d80d56ffa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cec675a9-f12c-4c7a-8466-8f3f470972ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c17c1f0-a3b2-4b52-a677-f0fd642e6d63",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.13 (RAG)",
   "language": "python",
   "name": "rag_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
